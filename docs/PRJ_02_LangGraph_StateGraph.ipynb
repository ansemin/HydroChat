{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env Environment Variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Basic Libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. StateGraph\n",
    "- A graph structure that operates based on state.\n",
    "- Practice: Restaurant Menu Recommendation System\n",
    "    - Recommends menus based on user preferences and provides information about the menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) State`\n",
    "- The state defines the structure of the data processed by the graph.\n",
    "- Overrides the existing state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "# Define State Schema - stores user preference, recommended menu, and menu information\n",
    "class MenuState(TypedDict):\n",
    "    user_preference: str\n",
    "    recommended_menu: str\n",
    "    menu_info: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Node`\n",
    "- A node is a function that performs the actual work in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_user_preference(state: MenuState) -> MenuState:\n",
    "    print(\"---Generating Random User Preference---\")\n",
    "    preferences = [\"Meat\", \"Seafood\", \"Vegetarian\", \"Anything\"]\n",
    "    preference = random.choice(preferences)\n",
    "    print(f\"Generated Preference: {preference}\")\n",
    "    return {\"user_preference\": preference}\n",
    "\n",
    "def recommend_menu(state: MenuState) -> MenuState:\n",
    "    print(\"---Recommending Menu---\")\n",
    "    preference = state['user_preference']\n",
    "    if preference == \"Meat\":\n",
    "        menu = \"Steak\"\n",
    "    elif preference == \"Seafood\":\n",
    "        menu = \"Lobster Pasta\"\n",
    "    elif preference == \"Vegetarian\":\n",
    "        menu = \"Green Salad\"\n",
    "    else:\n",
    "        menu = \"Chef's Special of the Day\"\n",
    "    print(f\"Recommended Menu: {menu}\")\n",
    "    return {\"recommended_menu\": menu}\n",
    "\n",
    "def provide_menu_info(state: MenuState) -> MenuState:\n",
    "    print(\"---Providing Menu Information---\")\n",
    "    menu = state['recommended_menu']\n",
    "    if menu == \"Steak\":\n",
    "        info = \"A juicy steak made with the finest beef. Price: 30,000 KRW\"\n",
    "    elif menu == \"Lobster Pasta\":\n",
    "        info = \"A harmony of fresh lobster and al dente pasta. Price: 28,000 KRW\"\n",
    "    elif menu == \"Green Salad\":\n",
    "        info = \"A healthy salad made with fresh organic vegetables. Price: 15,000 KRW\"\n",
    "    else:\n",
    "        info = \"A special dish carefully selected by the chef daily. Price: 35,000 KRW\"\n",
    "    print(f\"Menu Information: {info}\")\n",
    "    return {\"menu_info\": info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Graph Construction`\n",
    "- Build the entire graph using the defined components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Create Graph Builder\n",
    "builder = StateGraph(MenuState)\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\"get_preference\", get_user_preference)\n",
    "builder.add_node(\"recommend\", recommend_menu)\n",
    "builder.add_node(\"provide_info\", provide_menu_info)\n",
    "\n",
    "# Add Edges\n",
    "builder.add_edge(START, \"get_preference\")\n",
    "builder.add_edge(\"get_preference\", \"recommend\")\n",
    "builder.add_edge(\"recommend\", \"provide_info\")\n",
    "builder.add_edge(\"provide_info\", END)\n",
    "\n",
    "# Compile Graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAGwAJwDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGBAcIAgEDCf/EAFMQAAEDBAADAwYHDQUFBQkAAAEAAgMEBQYRBxIhFTGUExQiQVbTCBYXUVRV0SYyNmFxdHWTlbKz0tQjN0RSoTM1coGxJFORpPAJGDRCZIKio8H/xAAbAQEBAAMBAQEAAAAAAAAAAAAAAQIDBQQGB//EADURAAIAAwMICQQDAQEAAAAAAAABAgMRElGRBBQhMUFSYdEFEzNicZKhscEVIiOBMuHwU8L/2gAMAwEAAhEDEQA/AP6poiIAiIgC8SyshjL5HtjY3vc46A/5qJvV4qY6qO12tjJbrOwyc8zS6Gmj3rykmiCeuw1gILyCAQGuc3EiwG1Tyiou0br/AFnU+WuepQ3fTTI9cjBrp6LR+PeyVuUEKVY3T3LS8kXZRZmEh12oQR6jUs+1fPjVZfrig8Sz7V8GKWRoAFnoAB0AFKz7F9+Ktl+p6DwzPsWX4ePoXQPjVZfrig8Sz7U+NVl+uKDxLPtT4q2X6noPDM+xPirZfqeg8Mz7E/Dx9BoHxqsv1xQeJZ9qfGqy/XFB4ln2p8VbL9T0HhmfYnxVsv1PQeGZ9ifh4+g0D41WX64oPEs+1ZFJebfXv5KWupql/wDlhma4/wChWP8AFWy/U9B4Zn2LHrMHx2vj5Kiw22Zvq5qRmx130Otjr12E/Dx9CaCcRVZ1rrcQaai2S1dxtbBuW1yvM0sbf80D3HmJH/duJBHRvLrTrHR1kNwpIammkbNTzMD45Gno5p6grCOCyrULqv8AaxQ/ZERaiBERAEREAREQFXwHVwt9Ze36dPdaqSbm+aFriyFv4gI2tOh05nOPrJNoVY4bjyGI0tE7Ylt8ktDICNaMUjmb/IQAR84IKs69GUdrEuPps9CvWFDZhmNmwDHK2/5BcI7ZaKNodPUygkN24NaAACXEucAAASSQANlTKofHK0Wi+cMLxR3yy3i/W55hL6TH43Pr2uEzCyWENIdzRuDZOnX0D0d3HzkKjnXwqMYxfGcbvltirrvRXe/Q2Z5FtrGSU+yPKuMXkDJztaQWxloLyfR3ohWPKvhDYFhFPbJr5d6m3suNI2vhElqrC5k... [truncated]",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize Graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---랜덤 사용자 선호도 생성---\n",
      "생성된 선호도: 아무거나\n",
      "---메뉴 추천---\n",
      "추천 메뉴: 오늘의 쉐프 특선\n",
      "---메뉴 정보 제공---\n",
      "메뉴 정보: 쉐프가 그날그날 엄선한 특별 요리입니다. 가격: 35,000원\n",
      "\n",
      "=== 결과 ===\n",
      "선호도: 아무거나\n",
      "추천 메뉴: 오늘의 쉐프 특선\n",
      "메뉴 정보: 쉐프가 그날그날 엄선한 특별 요리입니다. 가격: 35,000원\n",
      "============\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "---랜덤 사용자 선호도 생성---\n",
      "생성된 선호도: 육류\n",
      "---메뉴 추천---\n",
      "추천 메뉴: 스테이크\n",
      "---메뉴 정보 제공---\n",
      "메뉴 정보: 최상급 소고기로 만든 juicy한 스��이크입니다. 가격: 30,000원\n",
      "\n",
      "=== 결과 ===\n",
      "선호도: 육류\n",
      "추천 메뉴: 스테이크\n",
      "메뉴 정보: 최상급 소고기로 만든 juicy한 스테이크입니다. 가격: 30,000원\n",
      "============\n",
      "\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute Graph\n",
    "\n",
    "def print_result(result: MenuState):\n",
    "    print(\"\\n=== Result ===\")\n",
    "    print(\"Preference:\", result['user_preference'])\n",
    "    print(\"Recommended Menu:\", result['recommended_menu'])\n",
    "    print(\"Menu Information:\", result['menu_info'])\n",
    "    print(\"============\\n\")\n",
    "\n",
    "\n",
    "# Initial Input\n",
    "inputs = {\"user_preference\": \"\"}\n",
    "\n",
    "# Test by running multiple times\n",
    "for _ in range(2):\n",
    "    result = graph.invoke(inputs)\n",
    "    print_result(result)\n",
    "    print(\"*\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conditional Edge\n",
    "- Edges define the connections between nodes.\n",
    "- Conditional Edge: Proceeds to a different path depending on whether the user input is menu-related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) State Definition`\n",
    "- If the user input is a menu recommendation, search the vector store and execute the RAG Chain.\n",
    "- Otherwise, the LLM generates a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# State Schema\n",
    "class MenuState(TypedDict):\n",
    "    user_query: str\n",
    "    is_menu_related: bool\n",
    "    search_results: List[str]\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) Vector Store Search Tool`\n",
    "- Initialize the vector store for menu search (load existing store)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3\") \n",
    "\n",
    "# Load Chroma Index\n",
    "vector_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) Node`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM Model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def get_user_query(state: MenuState) -> MenuState:\n",
    "    user_query = input(\"How can I help you? \")\n",
    "    return {\"user_query\": user_query}\n",
    "\n",
    "def analyze_input(state: MenuState) -> MenuState:\n",
    "    analyze_template = \"\"\"\n",
    "    Analyze the user's input to determine if it is a question about a restaurant menu recommendation or food information.\n",
    "\n",
    "    User Input: {user_query}\n",
    "\n",
    "    Answer \"True\" if it is a question about a restaurant menu or food information, otherwise answer \"False\".\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    analyze_prompt = ChatPromptTemplate.from_template(analyze_template)\n",
    "    analyze_chain = analyze_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    result = analyze_chain.invoke({\"user_query\": state['user_query']})\n",
    "    is_menu_related = result.strip().lower() == \"true\"\n",
    "    \n",
    "    return {\"is_menu_related\": is_menu_related}\n",
    "\n",
    "def search_menu_info(state: MenuState) -> MenuState:\n",
    "    # Search for up to 2 documents in the vector store\n",
    "    results = vector_db.similarity_search(state['user_query'], k=2)\n",
    "    search_results = [doc.page_content for doc in results]\n",
    "    return {\"search_results\": search_results}\n",
    "\n",
    "def generate_menu_response(state: MenuState) -> MenuState:\n",
    "    response_template = \"\"\"\n",
    "    User Input: {user_query}\n",
    "    Menu-related Search Results: {search_results}\n",
    "\n",
    "    Based on the information above, generate a detailed answer to the user's menu-related question.\n",
    "    Use the information from the search results to provide accurate and useful information.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    response_prompt = ChatPromptTemplate.from_template(response_template)\n",
    "    response_chain = response_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    final_answer = response_chain.invoke({\"user_query\": state['user_query'], \"search_results\": state['search_results']})\n",
    "    print(f\"\\nMenu Assistant: {final_answer}\")\n",
    "    \n",
    "    return {\"final_answer\": final_answer}\n",
    "\n",
    "def generate_general_response(state: MenuState) -> MenuState:\n",
    "    response_template = \"\"\"\n",
    "    User Input: {user_query}\n",
    "\n",
    "    The above input is not related to a restaurant menu or food.\n",
    "    Generate an appropriate response in a general conversational context.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    response_prompt = ChatPromptTemplate.from_template(response_template)\n",
    "    response_chain = response_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    final_answer = response_chain.invoke({\"user_query\": state['user_query']})\n",
    "    print(f\"\\nGeneral Assistant: {final_answer}\")\n",
    "    \n",
    "    return {\"final_answer\": final_answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) Edge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_next_step(state: MenuState) -> Literal[\"search_menu_info\", \"generate_general_response\"]:\n",
    "    if state['is_menu_related']:\n",
    "        return \"search_menu_info\"  \n",
    "    else:\n",
    "        return \"generate_general_response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) Graph Construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Graph Construction\n",
    "builder = StateGraph(MenuState)\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\"get_user_query\", get_user_query)\n",
    "builder.add_node(\"analyze_input\", analyze_input)\n",
    "builder.add_node(\"search_menu_info\", search_menu_info)\n",
    "builder.add_node(\"generate_menu_response\", generate_menu_response)\n",
    "builder.add_node(\"generate_general_response\", generate_general_response)\n",
    "\n",
    "# Add Edges\n",
    "builder.add_edge(START, \"get_user_query\")\n",
    "builder.add_edge(\"get_user_query\", \"analyze_input\")\n",
    "\n",
    "# Add Conditional Edges\n",
    "builder.add_conditional_edges(\n",
    "    \"analyze_input\",\n",
    "    decide_next_step,\n",
    "    {\n",
    "        \"search_menu_info\": \"search_menu_info\",\n",
    "        \"generate_general_response\": \"generate_general_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"search_menu_info\", \"generate_menu_response\")\n",
    "builder.add_edge(\"generate_menu_response\", END)\n",
    "builder.add_edge(\"generate_general_response\", END)\n",
    "\n",
    "# Compile Graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAITAfoDASIAAhEBAxEB/8QAHQABAAMBAQEBAQEAAAAAAAAAAAUGBwQIAwIBCf/EAFgQAAEEAQIDAQsGCQgHBwIHAAEAAgMEBQYRBxIhEwgUFRYXIjFBVpTTMlFUYZPSIzZVY3F1lbLRNVJzdIGRs9QkJTM0N1O0QkNicqGisQmCGER2g4SFwf/EABoBAQEAAwEBAAAAAAAAAAAAAAABAgMEBQb/xAA3EQEAAQICBgcHAwUBAQAAAAAAAQIRAxIUIVFSkaEEMUFxktHSBRMzYWKxwSOB4RUiMsLwY+L/2gAMAwEAAhEDEQA/AP8AVNERAREQEREBERAREQEREBERAREQEREBERAREQEREBERARcOYy8GEoPtTh8mxDWQxDmkleejWMHrcT0H/qQNyoUaWm1EO31HK+Zjx0xMMpbWiG/ody7GV3qJcS35mj17aaImM1U2j/upbJmxqDF1JCyfJVIXjoWyTtaR/YSvl41YX8sUPeWfxXyr6M0/Uj7ODBY2Fn82OnG0f3AL6+KuF/I9D3Zn8Fn+j8+S6jxqwv5Yoe8s/injVhfyxQ95Z/FPFXC/keh7sz+CeKuF/I9D3Zn8E/R+fI1HjVhfyxQ95Z/FPGrC/lih7yz+KeKuF/I9D3Zn8E8VcL+R6HuzP4J+j8+RqPGrC/lih7yz+K/UepcRK8MZlaT3H0NbYYSf/VfnxVwv5Hoe7M/gvxJpHBTMLJMLjntPpa6pGR/8J+j8+SaksHBwBBBB6gj1r+qsu0RBjHGfT0pwdgEu7GEb1JSfU+H0bb+tnK76/TvJYLNHLRTRzwGlkazuztVC7m5HepzXbDnY4dWu2G49Ia4OaMaqItmom8cy2xKIiLSgiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgrEu2X4gRwPDXQ4em201p3/wBvOZI2u+bdrI5R/wDulWdVmm3vLiLk2u32v46vLEeXoTFJI2Tr9Qli/vVmXRjddMR1Wj+ed1kREXOjN6HdC6EzNnOVsVl5spZw9ezZsNqY+1Ix7YDyy9k8RFsxa4hpERcdyBsoThv3TmmdZ8IK+vMq23gazYYHXYZ... [truncated]",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize Graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) Execute Graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "메뉴 어시스턴트: 스테이크 메뉴�� 가격은 다음과 같습니다:\n",
      "\n",
      "1. **시그니처 스테이크**  \n",
      "   - **가격**: ₩35,000  \n",
      "   - **주요 식재료**: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스  \n",
      "   - **설명**: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용하며 미디엄 레어로 조리하여 육즙을 최대한 보존합니다. 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여지며, 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.\n",
      "\n",
      "2. **안심 스테이크 샐러드**  \n",
      "   - **가격**: ₩26,000  \n",
      "   - **주요 식재료**: 소고기 안심, 루꼴라, 체리 토마토, 발사믹 글레이즈  \n",
      "   - **설명**: 부드러운 안심 스테이크를 얇게 슬라이스하여 신선한 루꼴라 위에 올린 메인 요리 샐러드입니다. 체리 토마토와 파마산 치즈 플레이크로 풍미를 더하고, 발사믹 글레이즈로 마무리하여 고기의 풍미를 한층 끌어올렸습니다.\n",
      "\n",
      "이 외에 궁금한 점이 있으면 언제든지 말씀해 주세요!\n",
      "\n",
      "일반 어시스턴트: 미국의 수도는 워��턴 D.C.입니다.\n",
      "대화를 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    initial_state = {'user_query':''}\n",
    "    graph.invoke(initial_state) \n",
    "    continue_chat = input(\"Do you have any other questions? (y/n): \").lower()\n",
    "    if continue_chat != 'y':\n",
    "        print(\"Ending the conversation. Thank you!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-agent-fZJ3tIVY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}